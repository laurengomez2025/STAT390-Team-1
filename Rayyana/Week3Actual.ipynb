{
  "cells": [
    {
      "cell_type": "raw",
      "id": "93809048",
      "metadata": {
        "id": "93809048"
      },
      "source": [
        "---\n",
        "title: \"Test Round\"\n",
        "format:\n",
        "  html:\n",
        "    toc: true\n",
        "    toc-title: Contents\n",
        "    toc-depth: 4\n",
        "    code-fold: show\n",
        "    self-contained: true\n",
        "    html-math-method: mathml\n",
        "jupyter: python3\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a47a36ce",
      "metadata": {
        "id": "a47a36ce"
      },
      "source": [
        "Write an algorithm that extracts / identifies the epithelium layer in the conjunctival lesion image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af1c2919",
      "metadata": {
        "id": "af1c2919"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage import io"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_paths = ['h2114153h&e.tif', 'h2114153melan.tif', 'h2114153melan2.tif', 'h2114153sox10.tif',\n",
        "               'h2114154h&e.tif', 'h2114154h&e2.tif', 'h2114154melan.tif', 'h2114154melan2.tif', 'h2114154sox10.tif',\n",
        "               'h2114156h&e.tif', 'h2114156h&e2.tif', 'h2114156melan.tif', 'h2114156melan2.tif', 'h2114156sox10.tif',\n",
        "               'h2114157h&e.tif', 'h2114157sox10.tif',\n",
        "               'h2114158h&e.tif', 'h2114158h&e2.tif', 'h2114158melan.tif', 'h2114158melan2.tif']\n",
        "\n",
        "def compare_images_pairwise(image_paths):\n",
        "\n",
        "    histograms = []\n",
        "    images = []\n",
        "\n",
        "    # loop through to do more than two images\n",
        "    for path in image_paths:\n",
        "        # Load the image\n",
        "        image = cv2.imread(path)\n",
        "        if image is None:\n",
        "            print(f\"Error loading image: {path}\")\n",
        "            continue\n",
        "\n",
        "        # HSV configuration\n",
        "        image_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "        # Compute the histogram for the image\n",
        "        hist = cv2.calcHist([image_hsv], [0, 1, 2], None, [50, 60, 60], [0, 180, 0, 256, 0, 256])\n",
        "        cv2.normalize(hist, hist)\n",
        "\n",
        "        # histogram list allows you to go through more than one\n",
        "        histograms.append(hist)\n",
        "        images.append(path)\n",
        "\n",
        "    # comparison\n",
        "    for i in range(len(histograms)):\n",
        "        for j in range(i + 1, len(histograms)):  # Avoid self-comparison and redundant comparisons\n",
        "            similarity = cv2.compareHist(histograms[i], histograms[j], cv2.HISTCMP_CORREL)\n",
        "            print(f'Similarity between {images[i]} and {images[j]}: {similarity}')\n",
        "\n",
        "print(f'Similarity between the two images: {similarity}')"
      ],
      "metadata": {
        "id": "9BRA0YuCe5tM"
      },
      "id": "9BRA0YuCe5tM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_paths = ['h2114153h&e.tif', 'h2114153melan.tif', 'h2114153melan2.tif', 'h2114153sox10.tif',\n",
        "               'h2114154h&e.tif', 'h2114154h&e2.tif', 'h2114154melan.tif', 'h2114154melan2.tif', 'h2114154sox10.tif',\n",
        "               'h2114156h&e.tif', 'h2114156h&e2.tif', 'h2114156melan.tif', 'h2114156melan2.tif', 'h2114156sox10.tif',\n",
        "               'h2114157h&e.tif', 'h2114157sox10.tif',\n",
        "               'h2114158h&e.tif', 'h2114158h&e2.tif', 'h2114158melan.tif', 'h2114158melan2.tif']\n",
        "\n",
        "def compare_images(image_paths):\n",
        "    # ORB feature detector\n",
        "    orb = cv2.ORB_create()\n",
        "\n",
        "    # Loop through the image pairs\n",
        "    for i in range(len(image_paths)):\n",
        "        for j in range(i + 1, len(image_paths)):\n",
        "\n",
        "            # still doing it pairwise, just multiple iterations instead\n",
        "            # grayscale for simplicity and understanding shape a bit better\n",
        "            img1 = cv2.imread(image_paths[i], 0)\n",
        "            img2 = cv2.imread(image_paths[j], 0)\n",
        "\n",
        "            edges1 = cv2.Canny(img1, 100, 200)\n",
        "            edges2 = cv2.Canny(img2, 100, 200)\n",
        "\n",
        "            # Feature Matching using ORB\n",
        "            keypoints1, descriptors1 = orb.detectAndCompute(edges1, None)\n",
        "            keypoints2, descriptors2 = orb.detectAndCompute(edges2, None)\n",
        "\n",
        "            # Brute Force Matcher with cross-check via norm_hamming distancing\n",
        "            bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
        "            matches = bf.match(descriptors1, descriptors2)\n",
        "\n",
        "            matches = sorted(matches, key=lambda x: x.distance)\n",
        "\n",
        "            # actually seeing every image\n",
        "            matched_img = cv2.drawMatches(edges1, keypoints1, edges2, keypoints2, matches[:50], None, flags=2)\n",
        "            cv2.imshow(f'Matches between {image_paths[i]} and {image_paths[j]}', matched_img)\n",
        "            cv2.waitKey(0)\n",
        "            cv2.destroyAllWindows()\n",
        "\n",
        "            if len(matches) > 10:\n",
        "                src_pts = np.float32([keypoints1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
        "                dst_pts = np.float32([keypoints2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
        "\n",
        "                M, _ = cv2.estimateAffinePartial2D(src_pts, dst_pts)\n",
        "\n",
        "                aligned_img2 = cv2.warpAffine(img2, M, (img1.shape[1], img1.shape[0]))\n",
        "\n",
        "                # Structural Similarity Index (SSIM)\n",
        "                similarity_score, diff = ssim(img1, aligned_img2, full=True)\n",
        "                print(f'Structural Similarity between {image_paths[i]} and {image_paths[j]}: {similarity_score:.4f}')\n",
        "\n",
        "                # Compare specific patches\n",
        "                x, y, w, h = 100, 100, 50, 50\n",
        "                patch1 = img1[y:y+h, x:x+w]\n",
        "                patch2 = aligned_img2[y:y+h, x:x+w]\n",
        "\n",
        "                patch_similarity, patch_diff = ssim(patch1, patch2, full=True)\n",
        "                print(f'Structural Similarity for patch between {image_paths[i]} and {image_paths[j]}: {patch_similarity:.4f}')\n",
        "\n",
        "            else:\n",
        "                print(f\"Not enough matches between {image_paths[i]} and {image_paths[j]}\")\n",
        "\n",
        "# Compare images pairwise\n",
        "compare_images(image_paths)"
      ],
      "metadata": {
        "id": "QJCC-Lfv-zIR"
      },
      "id": "QJCC-Lfv-zIR",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}