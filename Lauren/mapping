# In the code, we use ORB to detect and match keypoints between the two images. 
# The matched keypoints estimate an affine transformation that aligns the second stained image to the first.
# The visualization shows structural similarities between the images, where the colored
 # lines show regions of interest that correspond between the two images.  

import cv2
import numpy as np
from skimage.metrics import structural_similarity as ssim
from skimage import io

# Load two stained images; both H&E for the time being 
img1 = cv2.imread('image_1.jpg', 0)  # Image from stain 1
img2 = cv2.imread('image_2.jpg', 0)  # Image from stain 2

# Edge Detection to highlight structural features
edges1 = cv2.Canny(img1, 100, 200)
edges2 = cv2.Canny(img2, 100, 200)

# Feature Matching using ORB
orb = cv2.ORB_create()
keypoints1, descriptors1 = orb.detectAndCompute(edges1, None)
keypoints2, descriptors2 = orb.detectAndCompute(edges2, None)

# Use Brute Force Matcher
bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)
matches = bf.match(descriptors1, descriptors2)
matches = sorted(matches, key=lambda x: x.distance)

# Visualize the matched features
matched_img = cv2.drawMatches(edges1, keypoints1, edges2, keypoints2, matches[:50], None, flags=2)
cv2.imshow('Matches', matched_img)
cv2.waitKey(0)
cv2.destroyAllWindows()
